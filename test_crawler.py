#!/usr/bin/env python3
"""
æ•°æ®çˆ¬è™«ç³»ç»Ÿæµ‹è¯•è„šæœ¬
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend', 'src'))

import asyncio
from crawler.crawler import (
    CrawlerScheduler, DataStore, CrawlResult, CrawlTask,
    CBIRCrawler, InsuranceCompanyCrawler, create_default_scheduler
)
from crawler.parser import ClauseParser, parse_clause, extract_structured_data
from datetime import datetime


def test_crawl_result():
    """æµ‹è¯•çˆ¬å–ç»“æœæ¨¡å‹"""
    print("=" * 60)
    print("ğŸ“¦ æµ‹è¯• CrawlResult æ¨¡å‹")
    print("=" * 60)

    result = CrawlResult(
        url="https://example.com/policy/1",
        title="å…³äºè§„èŒƒäººèº«ä¿é™©ä¸šåŠ¡çš„é€šçŸ¥",
        content="è¿™æ˜¯æ”¿ç­–å†…å®¹...",
        source="é“¶ä¿ç›‘ä¼š",
        category="ç›‘ç®¡æ”¿ç­–",
        published_at=datetime.now()
    )

    print(f"âœ… åˆ›å»ºçˆ¬å–ç»“æœ")
    print(f"   æ ‡é¢˜: {result.title}")
    print(f"   æ¥æº: {result.source}")
    print(f"   ç±»åˆ«: {result.category}")
    print(f"   å“ˆå¸ŒID: {result.hash_id}")

    return True


def test_data_store():
    """æµ‹è¯•æ•°æ®å­˜å‚¨"""
    print("\n" + "=" * 60)
    print("ğŸ’¾ æµ‹è¯• DataStore")
    print("=" * 60)

    # ä½¿ç”¨å†…å­˜å­˜å‚¨æµ‹è¯•
    store = DataStore(db_path="/tmp/test_crawl_data.json")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    results = [
        CrawlResult(
            url=f"https://example.com/{i}",
            title=f"æµ‹è¯•æ¡æ¬¾{i}",
            content=f"å†…å®¹{i}",
            source="æµ‹è¯•æº",
            category="äº§å“æ¡æ¬¾"
        )
        for i in range(5)
    ]

    # ä¿å­˜
    saved = store.save_results(results)
    print(f"âœ… ä¿å­˜äº† {saved} æ¡æ•°æ®")

    # æŸ¥è¯¢
    query_results = store.query(category="äº§å“æ¡æ¬¾", limit=3)
    print(f"âœ… æŸ¥è¯¢åˆ° {len(query_results)} æ¡æ•°æ®")

    # ç»Ÿè®¡
    stats = store.get_stats()
    print(f"âœ… ç»Ÿè®¡: {stats}")

    # å»é‡æµ‹è¯•
    duplicate = store.save_result(results[0])
    print(f"âœ… é‡å¤æ•°æ®æ£€æµ‹: {'é€šè¿‡' if not duplicate else 'å¤±è´¥'}")

    return True


def test_clause_parser():
    """æµ‹è¯•æ¡æ¬¾è§£æå™¨"""
    print("\n" + "=" * 60)
    print("ğŸ“„ æµ‹è¯• ClauseParser")
    print("=" * 60)

    # ç¤ºä¾‹æ¡æ¬¾æ–‡æœ¬
    sample_clause = """
    ç¬¬ä¸€ç«  ä¿é™©è´£ä»»
    ç¬¬1æ¡ ç­‰å¾…æœŸ
    æœ¬åˆåŒç”Ÿæ•ˆä¹‹æ—¥èµ·90æ—¥å†…ï¼ˆå«ç¬¬90æ—¥ï¼‰ï¼Œè¢«ä¿é™©äººå› æ„å¤–ä¼¤å®³ä»¥å¤–çš„åŸå› ç¡®è¯Šåˆæ¬¡æ‚£æœ‰æœ¬åˆåŒæ‰€å®šä¹‰çš„é‡å¤§ç–¾ç—…ï¼Œæˆ‘ä»¬ä¸æ‰¿æ‹…ä¿é™©è´£ä»»ï¼Œä½†å°†é€€è¿˜æ‚¨æ‰€äº¤çº³çš„ä¿é™©è´¹ï¼Œæœ¬åˆåŒç»ˆæ­¢ã€‚

    ç¬¬2æ¡ ä¿é™©é‡‘é¢
    æœ¬åˆåŒçš„åŸºæœ¬ä¿é™©é‡‘é¢ä¸ºäººæ°‘å¸100,000å…ƒã€‚

    ç¬¬äºŒç«  è´£ä»»å…é™¤
    ç¬¬3æ¡ å…è´£æ¡æ¬¾
    å› ä¸‹åˆ—æƒ…å½¢ä¹‹ä¸€ï¼Œé€ æˆè¢«ä¿é™©äººèº«æ•…ã€ä¼¤æ®‹çš„ï¼Œæœ¬å…¬å¸ä¸æ‰¿æ‹…ç»™ä»˜ä¿é™©é‡‘çš„è´£ä»»ï¼š
    ï¼ˆä¸€ï¼‰æŠ•ä¿äººå¯¹è¢«ä¿é™©äººçš„æ•…æ„æ€å®³ã€æ•…æ„ä¼¤å®³ï¼›
    ï¼ˆäºŒï¼‰è¢«ä¿é™©äººæ•…æ„çŠ¯ç½ªæˆ–æŠ—æ‹’ä¾æ³•é‡‡å–çš„åˆ‘äº‹å¼ºåˆ¶æªæ–½ï¼›
    ï¼ˆä¸‰ï¼‰è¢«ä¿é™©äººè‡ªæ€æˆ–æ•…æ„è‡ªä¼¤ï¼›
    ï¼ˆå››ï¼‰è¢«ä¿é™©äººé†‰é…’ã€å¸é£Ÿæˆ–æ³¨å°„æ¯’å“ï¼›
    ï¼ˆäº”ï¼‰è¢«ä¿é™©äººé…’åé©¾é©¶ã€‚

    ç¬¬ä¸‰ç«  ä¿é™©è´¹
    ç¬¬4æ¡ å®½é™æœŸ
    åˆ†æœŸäº¤çº³ä¿é™©è´¹çš„ï¼Œåˆ°æœŸæœªäº¤çº³çš„ï¼Œè‡ªçº¦å®šæ—¥çš„æ¬¡æ—¥é›¶æ—¶èµ·60æ—¥ä¸ºå®½é™æœŸã€‚
    """

    parser = ClauseParser()

    # è§£ææ¡æ¬¾
    clause = parser.parse(sample_clause, "æµ‹è¯•é‡ç–¾é™©", "æµ‹è¯•ä¿é™©")

    print(f"âœ… è§£ææ¡æ¬¾: {clause.product_name}")
    print(f"   äº§å“ç±»å‹: {clause.clause_type}")
    print(f"   ç« èŠ‚æ•°: {len(clause.sections)}")

    # æ‰“å°ç« èŠ‚ä¿¡æ¯
    print("\n   ç« èŠ‚è¯¦æƒ…:")
    for section in clause.sections:
        print(f"   - {section.title} ({section.clause_type.value})")

    # æå–å…³é”®æ—¥æœŸ
    key_dates = parser.extract_key_dates(sample_clause)
    print(f"\nâœ… æå–åˆ° {len(key_dates)} ä¸ªå…³é”®æ—¥æœŸ:")
    for date in key_dates:
        print(f"   - {date['type']}: {date['days']}å¤©")

    # æå–ä¿é¢
    amounts = parser.extract_coverage_amounts(sample_clause)
    print(f"\nâœ… æå–åˆ° {len(amounts)} ä¸ªä¿é¢ä¿¡æ¯")

    # ç”Ÿæˆé¢˜ç›®å»ºè®®
    suggestions = parser.generate_question_suggestions(clause)
    print(f"\nâœ… ç”Ÿæˆ {len(suggestions)} ä¸ªé¢˜ç›®å»ºè®®:")
    for i, sugg in enumerate(suggestions[:3], 1):
        print(f"   {i}. [{sugg['type']}] {sugg.get('suggested_question', 'N/A')[:50]}...")

    return True


def test_extract_structured_data():
    """æµ‹è¯•ç»“æ„åŒ–æ•°æ®æå–"""
    print("\n" + "=" * 60)
    print("ğŸ” æµ‹è¯•ç»“æ„åŒ–æ•°æ®æå–")
    print("=" * 60)

    sample_text = """
    XXé‡å¤§ç–¾ç—…ä¿é™©æ¡æ¬¾

    ä¿é™©è´£ä»»ï¼šè¢«ä¿é™©äººäºæœ¬åˆåŒç”Ÿæ•ˆä¹‹æ—¥èµ·90æ—¥å†…å› éæ„å¤–åŸå› ç¡®è¯Šé‡ç–¾ï¼Œé€€è¿˜ä¿è´¹ï¼›90æ—¥åç¡®è¯Šï¼Œç»™ä»˜ä¿é¢ã€‚
    ä¿é™©é‡‘é¢ï¼šåŸºæœ¬ä¿é¢50ä¸‡å…ƒã€‚

    è´£ä»»å…é™¤ï¼š
    ï¼ˆä¸€ï¼‰æŠ•ä¿äººå¯¹è¢«ä¿é™©äººçš„æ•…æ„æ€å®³ï¼›
    ï¼ˆäºŒï¼‰è¢«ä¿é™©äººæ•…æ„çŠ¯ç½ªï¼›
    ï¼ˆä¸‰ï¼‰è¢«ä¿é™©äººè‡ªæ€ï¼›
    ï¼ˆå››ï¼‰è¢«ä¿é™©äººé†‰é…’é©¾é©¶ã€‚

    ä¿é™©è´¹äº¤çº³ï¼šå¹´ç¼´ï¼Œå®½é™æœŸ60æ—¥ã€‚
    """

    data = extract_structured_data(sample_text)

    print(f"âœ… æå–ç»“æœ:")
    print(f"   äº§å“ç±»å‹: {data['product_type']}")
    print(f"   ç« èŠ‚æ•°: {data['sections_count']}")
    print(f"   å…³é”®æ—¥æœŸ: {data['key_dates']}")
    print(f"   ä¿é¢ä¿¡æ¯: {data['coverage_amounts']}")
    print(f"   è´£ä»»å…é™¤: {data['exclusions']}")
    print(f"   é¢˜ç›®å»ºè®®æ•°: {len(data['question_suggestions'])}")

    return True


async def test_crawler_scheduler():
    """æµ‹è¯•çˆ¬è™«è°ƒåº¦å™¨"""
    print("\n" + "=" * 60)
    print("ğŸ•·ï¸ æµ‹è¯• CrawlerScheduler")
    print("=" * 60)

    scheduler = create_default_scheduler()

    print(f"âœ… åˆ›å»ºäº†è°ƒåº¦å™¨ï¼ŒåŒ…å« {len(scheduler.crawlers)} ä¸ªçˆ¬è™«")

    for crawler in scheduler.crawlers:
        print(f"   - {crawler.source_name} ({crawler.base_url})")

    return True


async def test_cbir_crawler_mock():
    """æµ‹è¯•é“¶ä¿ç›‘ä¼šçˆ¬è™«ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ›ï¸ æµ‹è¯• CBIRCrawler (æ¨¡æ‹Ÿæ¨¡å¼)")
    print("=" * 60)

    # æ³¨æ„ï¼šå®é™…çˆ¬å–éœ€è¦ç½‘ç»œè¿æ¥ï¼Œè¿™é‡Œåªæµ‹è¯•ç»“æ„
    crawler = CBIRCrawler()

    print(f"âœ… åˆ›å»ºäº†çˆ¬è™«:")
    print(f"   åç§°: {crawler.source_name}")
    print(f"   åŸºç¡€URL: {crawler.base_url}")
    print(f"   å»¶è¿Ÿ: {crawler.delay}ç§’")

    # æµ‹è¯•URLå‘ç°ï¼ˆä¸å®é™…çˆ¬å–ï¼‰
    # urls = await crawler.discover_urls()
    # print(f"âœ… å‘ç° {len(urls)} ä¸ªURL")

    return True


def test_paragraph_parsing():
    """æµ‹è¯•æ®µè½è§£æ"""
    print("\n" + "=" * 60)
    print("ğŸ“ æµ‹è¯•å¤æ‚æ¡æ¬¾è§£æ")
    print("=" * 60)

    complex_clause = """
    ç­‰å¾…æœŸæ¡æ¬¾è¯¦è§£

    æœ¬ä¸»é™©åˆåŒç”Ÿæ•ˆä¹‹æ—¥èµ·90æ—¥å†…ï¼ˆå«ç¬¬90æ—¥ï¼‰ï¼Œè¢«ä¿é™©äººå› æ„å¤–ä¼¤å®³ä»¥å¤–çš„åŸå› ï¼Œç¡®è¯Šåˆæ¬¡æ‚£æœ‰æœ¬ä¸»é™©åˆåŒæ‰€å®šä¹‰çš„é‡å¤§ç–¾ç—…ï¼ˆæ— è®ºä¸€ç§æˆ–å¤šç§ï¼‰ï¼Œæˆ‘ä»¬ä¸æ‰¿æ‹…ä¿é™©è´£ä»»ï¼Œä½†å°†é€€è¿˜æ‚¨æ‰€äº¤çº³çš„ä¿é™©è´¹ï¼Œæœ¬ä¸»é™©åˆåŒç»ˆæ­¢ã€‚è¿™90æ—¥çš„æ—¶é—´ç§°ä¸ºç­‰å¾…æœŸã€‚

    ç¤ºä¾‹è®¡ç®—ï¼š
    å®¢æˆ·å¼ å…ˆç”Ÿäº2024å¹´3æœˆ15æ—¥æŠ•ä¿ï¼Œç­‰å¾…æœŸä»2024å¹´3æœˆ16æ—¥å¼€å§‹è®¡ç®—ï¼Œåˆ°2024å¹´6æœˆ13æ—¥ç»“æŸï¼ˆå…±90å¤©ï¼‰ã€‚
    è‹¥å¼ å…ˆç”Ÿåœ¨2024å¹´5æœˆ15æ—¥ï¼ˆç­‰å¾…æœŸå†…ï¼‰ç¡®è¯Šè‚ºç™Œï¼Œä¿é™©å…¬å¸é€€è¿˜ä¿è´¹ï¼›
    è‹¥å¼ å…ˆç”Ÿåœ¨2024å¹´7æœˆ1æ—¥ï¼ˆç­‰å¾…æœŸåï¼‰ç¡®è¯Šè‚ºç™Œï¼Œä¿é™©å…¬å¸ç»™ä»˜ä¿é™©é‡‘ã€‚

    ä¿é™©é‡‘é¢ä¸ä¿é™©è´¹
    åŸºæœ¬ä¿é™©é‡‘é¢ä¸ºäººæ°‘å¸100,000å…ƒã€‚æ‚¨å¯ä»¥é€‰æ‹©å¹´ç¼´æˆ–æœˆç¼´ï¼Œå¹´ç¼´ä¿è´¹ä¸º2,000å…ƒï¼Œæœˆç¼´ä¿è´¹ä¸º180å…ƒã€‚

    å®½é™æœŸæ¡æ¬¾
    å¦‚æœæ‚¨åˆ°æœŸæœªäº¤çº³ä¿é™©è´¹ï¼Œè‡ªä¿é™©è´¹çº¦å®šäº¤çº³æ—¥çš„æ¬¡æ—¥é›¶æ—¶èµ·60æ—¥ä¸ºå®½é™æœŸã€‚å®½é™æœŸå†…å‘ç”Ÿçš„ä¿é™©äº‹æ•…ï¼Œæˆ‘ä»¬ä»ä¼šæ‰¿æ‹…ä¿é™©è´£ä»»ï¼Œä½†åœ¨ç»™ä»˜ä¿é™©é‡‘æ—¶ä¼šæ‰£å‡æ‚¨æ¬ äº¤çš„ä¿é™©è´¹ã€‚
    """

    parser = ClauseParser()
    clause = parser.parse(complex_clause, "å¤æ‚é‡ç–¾é™©", "XXäººå¯¿")

    print(f"âœ… è§£æå¤æ‚æ¡æ¬¾:")
    print(f"   è¯†åˆ«ç±»å‹: {clause.clause_type}")
    print(f"   ç« èŠ‚æ•°é‡: {len(clause.sections)}")

    # åˆ†ææ¯ä¸ªç« èŠ‚
    for section in clause.sections:
        print(f"\n   [{section.clause_type.value}] {section.title}")
        if section.keywords:
            print(f"   å…³é”®è¯: {', '.join(section.keywords[:5])}")

    # æå–æ—¥æœŸä¿¡æ¯
    key_dates = parser.extract_key_dates(complex_clause)
    print(f"\nâœ… æå–æ—¥æœŸä¿¡æ¯:")
    for date in key_dates:
        print(f"   - {date['type']}: {date['days']}å¤© ({date['context']})")

    return True


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("ğŸ•·ï¸ æ•°æ®çˆ¬è™«ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)

    tests = [
        ("CrawlResultæ¨¡å‹", test_crawl_result),
        ("DataStoreå­˜å‚¨", test_data_store),
        ("ClauseParserè§£æ", test_clause_parser),
        ("ç»“æ„åŒ–æ•°æ®æå–", test_extract_structured_data),
        ("å¤æ‚æ¡æ¬¾è§£æ", test_paragraph_parsing),
    ]

    async_tests = [
        ("CrawlerSchedulerè°ƒåº¦å™¨", test_crawler_scheduler),
        ("CBIRCrawlerçˆ¬è™«", test_cbir_crawler_mock),
    ]

    results = []

    # è¿è¡ŒåŒæ­¥æµ‹è¯•
    for name, test_func in tests:
        print(f"\n{'='*60}")
        print(f"ğŸ”¹ è¿è¡Œæµ‹è¯•: {name}")
        print('='*60)
        try:
            success = test_func()
            results.append((name, success))
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))

    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    for name, test_func in async_tests:
        print(f"\n{'='*60}")
        print(f"ğŸ”¹ è¿è¡Œæµ‹è¯•: {name}")
        print('='*60)
        try:
            success = asyncio.run(test_func())
            results.append((name, success))
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))

    # æ€»ç»“
    print("\n\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {status}: {name}")

    all_passed = all(success for _, success in results)

    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®çˆ¬è™«ç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
        print("\nä¸»è¦åŠŸèƒ½:")
        print("  â€¢ å¤šæºçˆ¬è™«è°ƒåº¦ç®¡ç†")
        print("  â€¢ æ•°æ®å»é‡ä¸å­˜å‚¨")
        print("  â€¢ æ¡æ¬¾ç»“æ„åŒ–è§£æ")
        print("  â€¢ å…³é”®ä¿¡æ¯æå–ï¼ˆæ—¥æœŸã€é‡‘é¢ã€å…è´£æ¡æ¬¾ï¼‰")
        print("  â€¢ é¢˜ç›®å»ºè®®è‡ªåŠ¨ç”Ÿæˆ")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ã€‚è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")

    return 0 if all_passed else 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
