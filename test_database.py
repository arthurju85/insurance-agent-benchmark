#!/usr/bin/env python3
"""
æ•°æ®æŒä¹…åŒ–æµ‹è¯•è„šæœ¬
æµ‹è¯•æ•°æ®åº“çš„è¯»å†™åŠŸèƒ½
"""

import sys
import os

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend', 'src'))

from db.database import Database
from datetime import datetime


def test_database_init():
    """æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–"""
    print("=" * 50)
    print("ğŸ—„ï¸ æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–")
    print("=" * 50)

    # åˆ›å»ºå†…å­˜æ•°æ®åº“ç”¨äºæµ‹è¯•
    db = Database(":memory:")

    print("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")

    # éªŒè¯è¡¨æ˜¯å¦åˆ›å»º
    with db.get_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row['name'] for row in cursor.fetchall()]

        expected_tables = [
            'evaluations', 'evaluation_details', 'leaderboard_history',
            'arena_sessions', 'arena_events', 'registered_agents'
        ]

        for table in expected_tables:
            if table in tables:
                print(f"   âœ… è¡¨ {table} å·²åˆ›å»º")
            else:
                print(f"   âŒ è¡¨ {table} ç¼ºå¤±")

    return True


def test_save_evaluation(db):
    """æµ‹è¯•ä¿å­˜è¯„æµ‹ç»“æœ"""
    print("\n" + "=" * 50)
    print("ğŸ’¾ æµ‹è¯•ä¿å­˜è¯„æµ‹ç»“æœ")
    print("=" * 50)

    # æ¨¡æ‹Ÿè¯„æµ‹ç»“æœ
    evaluation = {
        "evaluation_id": "eval_20260115_001",
        "agent_id": "test-agent-1",
        "agent_name": "Test Agent",
        "agent_vendor": "Test Corp",
        "agent_version": "v1.0",
        "question_set_id": "benchmark_v1",
        "status": "completed",
        "total_score": 850.0,
        "max_total_score": 1000.0,
        "overall_percentage": 85.0,
        "total_questions": 10,
        "completed_questions": 10,
        "failed_questions": 0,
        "timeout_questions": 0,
        "total_latency_ms": 5000.0,
        "avg_latency_ms": 500.0,
        "tags": ["test", "benchmark"],
        "question_results": [
            {
                "question_id": "Q001",
                "dimension": "knowledge",
                "score": 90.0,
                "max_score": 100.0,
                "status": "completed",
                "latency_ms": 450.0,
                "agent_output": "test output",
                "validation_results": [{"rule_type": "keyword", "passed": True, "score": 100.0}]
            }
        ]
    }

    # ä¿å­˜
    eval_id = db.save_evaluation(evaluation)
    print(f"âœ… è¯„æµ‹ç»“æœå·²ä¿å­˜: {eval_id}")

    # è¯»å–
    retrieved = db.get_evaluation(eval_id)
    if retrieved:
        print(f"âœ… è¯„æµ‹ç»“æœå·²è¯»å–")
        print(f"   Agent: {retrieved['agent_name']}")
        print(f"   å¾—åˆ†: {retrieved['total_score']}/{retrieved['max_total_score']}")
        print(f"   ç™¾åˆ†æ¯”: {retrieved['overall_percentage']}%")
    else:
        print("âŒ æ— æ³•è¯»å–è¯„æµ‹ç»“æœ")
        return False

    return True


def test_leaderboard_operations():
    """æµ‹è¯•æ’è¡Œæ¦œæ“ä½œ"""
    print("\n" + "=" * 50)
    print("ğŸ† æµ‹è¯•æ’è¡Œæ¦œæ“ä½œ")
    print("=" * 50)

    db = Database(":memory:")

    # ä¿å­˜æ’è¡Œæ¦œ
    leaderboard = {
        "leaderboard_id": "lb_2026_01",
        "name": "2026å¹´1æœˆæ’è¡Œæ¦œ",
        "evaluation_date": "2026-01",
        "question_set_id": "benchmark_v1",
        "entries": [
            {
                "agent_id": "agent-1",
                "agent_name": "Agent One",
                "vendor": "Vendor A",
                "version": "v1.0",
                "agent_type": "insurer",
                "rank": 1,
                "overall_score": 920.0,
                "overall_percentage": 92.0,
                "knowledge_score": 95.0,
                "understanding_score": 90.0,
                "reasoning_score": 88.0,
                "compliance_score": 94.0,
                "tools_score": 91.0,
                "change": 2.5
            },
            {
                "agent_id": "agent-2",
                "agent_name": "Agent Two",
                "vendor": "Vendor B",
                "version": "v2.0",
                "agent_type": "tech",
                "rank": 2,
                "overall_score": 880.0,
                "overall_percentage": 88.0,
                "knowledge_score": 85.0,
                "understanding_score": 90.0,
                "reasoning_score": 87.0,
                "compliance_score": 92.0,
                "tools_score": 89.0,
                "change": -1.0
            }
        ]
    }

    db.save_leaderboard(leaderboard)
    print("âœ… æ’è¡Œæ¦œå·²ä¿å­˜")

    # è¯»å–
    retrieved = db.get_leaderboard("2026-01")
    if retrieved:
        print(f"âœ… æ’è¡Œæ¦œå·²è¯»å–: {retrieved['name']}")
        print(f"   æ¡ç›®æ•°: {len(retrieved['entries'])}")
        print(f"   ç¬¬ä¸€å: {retrieved['entries'][0]['agent_name']}")
    else:
        print("âŒ æ— æ³•è¯»å–æ’è¡Œæ¦œ")
        return False

    # æœ€æ–°æ’è¡Œæ¦œ
    latest = db.get_latest_leaderboard()
    if latest:
        print(f"âœ… æœ€æ–°æ’è¡Œæ¦œ: {latest['evaluation_date']}")

    return True


def test_agent_registration():
    """æµ‹è¯•Agentæ³¨å†Œ"""
    print("\n" + "=" * 50)
    print("ğŸ¤– æµ‹è¯•Agentæ³¨å†Œ")
    print("=" * 50)

    db = Database(":memory:")

    # æ³¨å†ŒAgent
    agent_config = {
        "id": "test-agent-001",
        "name": "Test Insurance Agent",
        "vendor": "Test Corp",
        "version": "v1.0.0",
        "agent_type": "openai_api",
        "base_url": "https://api.openai.com/v1",
        "model": "gpt-4",
        "system_prompt": "You are an insurance expert..."
    }

    agent_id = db.register_agent(agent_config)
    print(f"âœ… Agentå·²æ³¨å†Œ: {agent_id}")

    # åˆ—å‡ºAgent
    agents = db.get_registered_agents(active_only=True)
    print(f"âœ… å·²æ³¨å†ŒAgentæ•°: {len(agents)}")

    if agents:
        print(f"   åç§°: {agents[0]['name']}")
        print(f"   å‚å•†: {agents[0]['vendor']}")
        print(f"   æ¨¡å‹: {agents[0]['model']}")

    return True


def test_arena_operations():
    """æµ‹è¯•ç«æŠ€åœºæ“ä½œ"""
    print("\n" + "=" * 50)
    print("ğŸŸï¸ æµ‹è¯•ç«æŠ€åœºæ“ä½œ")
    print("=" * 50)

    db = Database(":memory:")

    # åˆ›å»ºä¼šè¯
    session_id = db.create_arena_session(
        "arena_test_001",
        "æµ‹è¯•ç«æŠ€åœº",
        {"duration": 60, "max_agents": 5}
    )
    print(f"âœ… ç«æŠ€åœºä¼šè¯å·²åˆ›å»º: {session_id}")

    # ä¿å­˜äº‹ä»¶
    db.save_arena_event(session_id, "customer_generated", {"customer_id": "C001"})
    db.save_arena_event(session_id, "deal_closed", {"agent_id": "A001", "amount": 10000})
    print("âœ… ç«æŠ€åœºäº‹ä»¶å·²ä¿å­˜")

    # è¯»å–äº‹ä»¶
    events = db.get_arena_events(session_id)
    print(f"âœ… äº‹ä»¶æ•°: {len(events)}")

    # ç»“æŸä¼šè¯
    db.finish_arena_session(session_id, {"winner": "A001"})
    print("âœ… ç«æŠ€åœºä¼šè¯å·²ç»“æŸ")

    return True


def test_statistics():
    """æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½")
    print("=" * 50)

    db = Database(":memory:")

    # æ·»åŠ ä¸€äº›æ•°æ®
    db.register_agent({
        "id": "agent-1",
        "name": "Agent 1",
        "vendor": "Vendor A",
        "agent_type": "openai_api",
        "model": "gpt-4"
    })

    db.save_evaluation({
        "evaluation_id": "eval_001",
        "agent_id": "agent-1",
        "agent_name": "Agent 1",
        "question_set_id": "test",
        "status": "completed",
        "total_score": 800,
        "max_total_score": 1000,
        "overall_percentage": 80.0,
        "question_results": []
    })

    # è·å–ç»Ÿè®¡
    stats = db.get_statistics()
    print("âœ… ç³»ç»Ÿç»Ÿè®¡:")
    print(f"   æ€»è¯„æµ‹æ•°: {stats['total_evaluations']}")
    print(f"   æ€»Agentæ•°: {stats['total_agents']}")
    print(f"   æ’è¡Œæ¦œæ•°: {stats['total_leaderboards']}")
    print(f"   è¿‘7å¤©è¯„æµ‹: {stats['recent_evaluations']}")

    return True


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 50)
    print("ğŸ—„ï¸ æ•°æ®æŒä¹…åŒ–æµ‹è¯•")
    print("=" * 50)

    tests = [
        ("æ•°æ®åº“åˆå§‹åŒ–", test_database_init),
        ("è¯„æµ‹ç»“æœä¿å­˜", test_save_evaluation),
        ("æ’è¡Œæ¦œæ“ä½œ", test_leaderboard_operations),
        ("Agentæ³¨å†Œ", test_agent_registration),
        ("ç«æŠ€åœºæ“ä½œ", test_arena_operations),
        ("ç»Ÿè®¡åŠŸèƒ½", test_statistics),
    ]

    results = []
    for name, test_func in tests:
        print(f"\nğŸ”¹ è¿è¡Œæµ‹è¯•: {name}")
        try:
            success = test_func()
            results.append((name, success))
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))

    # æ€»ç»“
    print("\n\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 50)
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {status}: {name}")

    all_passed = all(success for _, success in results)

    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®æŒä¹…åŒ–æ¨¡å—å·¥ä½œæ­£å¸¸ã€‚")
        print("\næ•°æ®åº“æ–‡ä»¶ä½ç½®:")
        print("  backend/data/insurance_benchmark.db")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ã€‚è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")

    return 0 if all_passed else 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
